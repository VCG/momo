{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    _         _                   _       \n",
      "   / \\   _ __| | _____  _   _  __| | __ _ \n",
      "  / _ \\ | '__| |/ / _ \\| | | |/ _` |/ _` |\n",
      " / ___ \\| |  |   < (_) | |_| | (_| | (_| |\n",
      "/_/   \\_\\_|  |_|\\_\\___/ \\__,_|\\__,_|\\__,_|\n",
      "                                          \n",
      "\n",
      "Client Version: v2024.04.19\n"
     ]
    }
   ],
   "source": [
    "import arkouda as ak\n",
    "import arachne as ar\n",
    "import scipy as sp\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import navis\n",
    "from fafbseg import flywire\n",
    "from compcon.navis_api import get_flywire_neuron, get_hemibrain_neuron\n",
    "from compcon.create_graph import get_neuron, get_graph, draw_graph, get_neuron_local, overall, draw_connection, draw3d_graph\n",
    "from compcon.isomporphic_subgraphs import find_isomorphic_subgraphs\n",
    "import itertools\n",
    "from skelescope.skelescope import Skelescope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %env ANYWIDGET_HMR=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('column_assignment.csv')\n",
    "\n",
    "# Extract root_id and column_id\n",
    "df = df[['root_id', 'column_id']]\n",
    "ids=[]\n",
    "for i in range(1):\n",
    "    ids.extend(df[df[\"column_id\"] == (i+1)][\"root_id\"].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_column(column):\n",
    "    return (column) / (1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ideally like this\n",
    "# viewer = Skelescope()\n",
    "# viewer.add_neuron_single(n1.nodes, n1.connectors, n1.edges, \"blue\")\n",
    "# viewer.add_neuron_single(n2.nodes, n2.connectors, n2.edges, \"red\")\n",
    "# viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "connected to arkouda server tcp://*:5555\n",
      "disconnected from arkouda server tcp://*:5555\n"
     ]
    }
   ],
   "source": [
    "g, d, n = overall(ids[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node Drawing Functionality\n",
    "\n",
    "- **Circular Nodes**:  \n",
    "  - Represent branches within the neuron (denoted as `\"n\"`).\n",
    "  - The user can freely draw and position these circular nodes, forming the core structure of the neuron.\n",
    "\n",
    "- **Triangular Nodes**:  \n",
    "  - Represent synaptic connections (denoted as `\"s\"`).\n",
    "  - **Note**: Triangular nodes can only be placed on edges that connect circular nodes.\n",
    "  - The user cannot draw triangular nodes independently; they must be positioned in relation to the existing connections between circular nodes.\n",
    "\n",
    "\n",
    "### Pipeline\n",
    "\n",
    "1. **Transform Columns into New Data Structure**  \n",
    "   - Process approximately 10 columns and transfrom them into the new data structure.\n",
    "\n",
    "2. **User Drawing**  \n",
    "   - Allow the user to draw a graph representing neuron branches and synapses.\n",
    "\n",
    "3. **Convert Drawing to Data Structure**  \n",
    "   - Take the user's drawing and transform it into the new data structure.\n",
    "\n",
    "4. **Search for Motifs Using `subgraph_isomorphism`**  \n",
    "   - Apply the `subgraph_isomorphism` function to detect specific motifs in the transformed data.\n",
    "\n",
    "5. **Convert Motifs into Skeleton or Alternate View**  \n",
    "   - Transform the identified motifs from the new data structure back into a skeleton or another specified view for further analysis.\n",
    "\n",
    "6. **Display Detected Motifs**  \n",
    "   - Present the found motifs to the user for visualization.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given: \n",
    "# branches = np.array([[1, 2], [2, 3], [3, 4], [4,5], [10, 20],[20, 30], [30, 40], [40,50]])\n",
    "branches = np.array([[1, 2], [2, 3], [3, 4], [10, 20],[20, 30], [30, 40]])\n",
    "\n",
    "neruon_id=[0,0,0, 1,1,1]\n",
    "\n",
    "branches_neuron = np.array([0, 0, 0, 1,1, 1])\n",
    "\n",
    "synapses = {\"S1\": {\n",
    "                     0: np.array([1, 2]), \n",
    "                     1: np.array([10, 20])\n",
    "                  },\n",
    "            \"S2\": {\n",
    "                     0: np.array([2, 3]), \n",
    "                     1: np.array([20, 30])\n",
    "                  },\n",
    "            # \"S3\": {\n",
    "            #          0: np.array([3, 4]), \n",
    "            #          1: np.array([30, 40])\n",
    "            #       }\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_graph_creation(edges):\n",
    "    first_elements = edges[:, 0]\n",
    "    second_elements = edges[:, 1]\n",
    "    neighbor_matrix = (first_elements[:, np.newaxis] == second_elements[np.newaxis, :])\n",
    "\n",
    "    # Step 3: Extract neighbor pairs\n",
    "    neighbor_indices = np.argwhere(neighbor_matrix)\n",
    "    neighbor_indices = neighbor_indices[neighbor_indices[:, 0] != neighbor_indices[:, 1]]\n",
    "    neighbor_pairs = edges[neighbor_indices]\n",
    "\n",
    "    # Step 4: Combine node indices to create unique identifiers for edges\n",
    "    src_combined = neighbor_pairs[:, 0, 0] * 10000 + neighbor_pairs[:, 0, 1]\n",
    "    dst_combined = neighbor_pairs[:, 1, 0] * 10000 + neighbor_pairs[:, 1, 1]\n",
    "\n",
    "    # Convert to lists for Arkouda\n",
    "    src = src_combined.astype(np.int64).tolist()\n",
    "    dst = dst_combined.astype(np.int64).tolist()\n",
    "    return src, dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawing_transformation(branches, synapses):\n",
    "    nodes=[]\n",
    "    branch_type= []\n",
    "    for b in branches:\n",
    "        nodes.append(b[0] * 10000 + b[1])\n",
    "\n",
    "    src, dst = test_graph_creation(branches)\n",
    "    for s in src:\n",
    "        branch_type.append(\"n\")\n",
    "\n",
    "    for s in synapses:\n",
    "        src.append(synapses[s][0][0] * 10000 + synapses[s][0][1])\n",
    "        dst.append(synapses[s][1][0] * 10000 + synapses[s][1][1])\n",
    "        branch_type.append(\"s\")\n",
    "    \n",
    "    return src, dst, branch_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(src, dst, branch_type):\n",
    "    ak.connect()\n",
    "    nx_display = nx.Graph()\n",
    "    for (u, v, etype) in zip(src, dst, branch_type):\n",
    "        nx_display.add_edge(u, v, edge_type=etype)\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    pos = nx.kamada_kawai_layout(nx_display)\n",
    "\n",
    "    edge_colors = [\"blue\" if nx_display[u][v]['edge_type'] == \"n\" else \"red\" if nx_display[u][v]['edge_type'] == \"s\" else \"black\" for u, v in nx_display.edges()]\n",
    "\n",
    "    nx.draw_networkx(nx_display, pos, with_labels=True, node_size=750, edge_color=edge_colors)\n",
    "    plt.show()\n",
    "    ak.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findd(g, subgraph):\n",
    "    ak.connect()\n",
    "    # find_isomorphic_subgraphs(g, subgraph)\n",
    "    src_sub, dst_sub = subgraph.edges()\n",
    "    src_sub = src_sub.to_ndarray()\n",
    "    dst_sub = dst_sub.to_ndarray()\n",
    "    isos = ar.subgraph_isomorphism(g, subgraph, semantic_check= True)\n",
    "    # print(f\"Isomorphisms found: {isos}\")\n",
    "    isos_ndarray = isos.to_ndarray()  # Convert pdarray to ndarray\n",
    "\n",
    "    # Check if the length of isomorphisms is a multiple of the number of subgraph nodes\n",
    "    if len(isos) % len(subgraph) != 0:\n",
    "        raise ValueError(\"The length of isomorphisms is not a multiple of the number of subgraph nodes.\")\n",
    "\n",
    "    subgraph_nodes = sorted(list(np.unique(np.concatenate((src_sub, dst_sub)))))\n",
    "    number_isos_found = len(isos) // len(subgraph_nodes)\n",
    "\n",
    "    # Prepare the hostgraph_nodes as a 2D array\n",
    "    hostgraph_nodes = isos_ndarray.reshape(-1, len(subgraph_nodes))\n",
    "\n",
    "    # Create all mappings at once using a list comprehension\n",
    "    all_mappings = [\n",
    "        dict(zip(subgraph_nodes, hostgraph_nodes[i]))\n",
    "        for i in range(number_isos_found)\n",
    "    ]\n",
    "\n",
    "    print(f\"Number of Mappings found: {number_isos_found}\")\n",
    "    return all_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_edges(subgraph, mapping):\n",
    "    edges = subgraph.edges()\n",
    "    src = edges[0].to_ndarray()\n",
    "    dst = edges[1].to_ndarray()\n",
    "\n",
    "    src_mapped = np.vectorize(mapping.get)(src)\n",
    "    dst_mapped = np.vectorize(mapping.get)(dst)\n",
    "\n",
    "    return src_mapped, dst_mapped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_transformation_edges(d, src_mapped, dst_mapped):\n",
    "    new_edges = []\n",
    "    n_ids = []\n",
    "    unique_offset = 0\n",
    "    for i in range(len(src_mapped)):\n",
    "        t = d[(d['src'] == src_mapped[i]) & (d['dst'] == dst_mapped[i])][0]\n",
    "        if t[\"connection_type\"] == 'n':\n",
    "            new_element = [t[\"s_bef\"], t[\"s_af\"]]\n",
    "            # wenn edges in verschiedenen neurons gleiche ids haben geht das nicht!!(check if n_ids übereinstimmen!)\n",
    "            if new_element not in new_edges:\n",
    "                new_edges.append(new_element)\n",
    "                n_ids.append(int(t[\"n_id\"]))\n",
    "\n",
    "            # new_edges_temp = new_edges\n",
    "            # if (len(np.unique(new_edges_temp, axis=0).tolist()) + unique_offset) != len(new_edges_temp):\n",
    "            #     unique_offset +=1\n",
    "            # else:\n",
    "            #     n_ids.append(int(t[\"n_id\"]))\n",
    "\n",
    "            new_element = [t[\"d_bef\"], t[\"d_af\"]]\n",
    "            if new_element not in new_edges:\n",
    "                new_edges.append(new_element)\n",
    "                n_ids.append(int(t[\"n_id\"]))\n",
    "\n",
    "            # new_edges_temp = new_edges\n",
    "            # if (len(np.unique(new_edges_temp, axis=0).tolist()) + unique_offset) != len(new_edges_temp):\n",
    "            #     unique_offset +=1\n",
    "            # else:\n",
    "            #     n_ids.append(int(t[\"n_id\"]))\n",
    "\n",
    "\n",
    "    # seen = set()\n",
    "    # seen_add = seen.add\n",
    "    # new_edges = [x for x in new_edges if not (x in seen or seen_add(x))]\n",
    "    # new_edges = np.unique(new_edges, axis=0).tolist()\n",
    "    return new_edges, n_ids\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segment_idx(new_edges, n_ids):\n",
    "    unique_n_ids = set(n_ids)\n",
    "    offset = 0\n",
    "    neuron3d = []\n",
    "    testlist = []\n",
    "    for i in unique_n_ids:\n",
    "        n, c = get_neuron_local(i, 3000, 1000)\n",
    "        for segment_idx, segment in enumerate(n.edges):\n",
    "            for edge_id, edge in enumerate(new_edges):\n",
    "                if n_ids[edge_id] == i:\n",
    "                    if (segment[0] == edge[0] and segment[1] == edge[1]):\n",
    "                        testlist.append(offset + segment_idx)\n",
    "        neuron3d.append(n)  \n",
    "        offset += len(n.edges)\n",
    "    return testlist, neuron3d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_neuron_list(neuron3d):\n",
    "    neuron_nodes = []\n",
    "    neuron_edges = []\n",
    "    neuron_segments = []\n",
    "    for n in neuron3d:\n",
    "        n.nodes['x'] = normalize_column(n.nodes['x'])\n",
    "        n.nodes['y'] = normalize_column(n.nodes['y'])\n",
    "        n.nodes['z'] = normalize_column(n.nodes['z'])\n",
    "\n",
    "        n.connectors['x'] = normalize_column(n.connectors['x'])\n",
    "        n.connectors['y'] = normalize_column(n.connectors['y'])\n",
    "        n.connectors['z'] = normalize_column(n.connectors['z'])\n",
    "\n",
    "        n.nodes.radius = 0.1\n",
    "        neuron_nodes.append(n.nodes)\n",
    "        neuron_edges.append(n.edges)\n",
    "        neuron_segments.append(n.segments)\n",
    "    \n",
    "    return neuron_nodes, neuron_edges, neuron_segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slabs(new_edges, n_ids):\n",
    "    paths = []\n",
    "    unique_n_ids = set(n_ids)\n",
    "    short_ids = []\n",
    "    nds_neurons = []\n",
    "\n",
    "    for index, id in enumerate(unique_n_ids):\n",
    "        n, c = get_neuron_local(id, 3000)\n",
    "        nx_display = nx.Graph()\n",
    "        nx_display.add_edges_from(n.edges)\n",
    "        shortest_path=[]\n",
    "        temp_paths=[]\n",
    "        for edge_index, edge in enumerate(new_edges):\n",
    "            if n_ids[edge_index]==id:\n",
    "                start_node_id = new_edges[edge_index][0]\n",
    "                end_node_id = new_edges[edge_index][1]\n",
    "                try:\n",
    "                    shortest_path = nx.shortest_path(nx_display, source=start_node_id, target=end_node_id, weight='weight')\n",
    "                    \n",
    "                except nx.NetworkXNoPath:\n",
    "                    print(f\"No path found between and\")\n",
    "\n",
    "                # shortest_path = np.stack([shortest_path[:-1], shortest_path[1:]], axis=1).tolist()\n",
    "                temp_paths.append(shortest_path)\n",
    "                short_ids.extend([id])\n",
    "        nds_neurons.append(n)\n",
    "        paths.append(temp_paths)\n",
    "    return paths, short_ids, nds_neurons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segment_idx_nds(final_path, paths): \n",
    "    # offset = 0\n",
    "    # neuron3d = []\n",
    "    # testlist = []\n",
    "\n",
    "    # for neuron in nds_neurons:\n",
    "    #     for segment_idx, segment in enumerate(neuron.edges):\n",
    "    #         for index, path in enumerate(paths):\n",
    "    #             if int(neuron.id) == short_ids[index]:\n",
    "    #                 for element in path:\n",
    "    #                     if (segment[0] == element[0] and segment[1] == element[1]):\n",
    "    #                         testlist.append(offset + segment_idx)\n",
    "    #     offset += len(neuron.edges)\n",
    "\n",
    "    # return testlist\n",
    "    offset = 0\n",
    "    testlist = []\n",
    "    for path in final_path:\n",
    "        for segment_idx, segment in enumerate(path):\n",
    "            for hh in paths:\n",
    "                for h in hh:\n",
    "                    if segment == h:\n",
    "                        testlist.append(offset + segment_idx)\n",
    "                        # print(h)\n",
    "        offset += len(path)\n",
    "    return testlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_subsequence_if_exists(list1, list2):\n",
    "    # Find the starting index of list2 in list1\n",
    "    n, m = len(list1), len(list2)\n",
    "    \n",
    "    # Iterate over list1 to find a matching subsequence\n",
    "    for i in range(n - m + 1):\n",
    "        if list1[i:i + m] == list2:  # Check if list2 matches list1 starting at index i\n",
    "            # print(list1)\n",
    "            print(list2)\n",
    "            if i==0:\n",
    "                # print(list1[i + m-1:])\n",
    "                return list1[i + m-1:]\n",
    "            \n",
    "            \n",
    "            if (i+m) == len(list1):\n",
    "                # print(list1[:i+1])\n",
    "                return list1[:i+1]\n",
    "            # print(list1[:i+1], list1[i + m-1:])\n",
    "            return list1[:i+1], list1[i + m-1:]  # Remove the subsequence\n",
    "    \n",
    "    # If no matching subsequence is found, return the original list\n",
    "    return list1\n",
    "\n",
    "# Example usage:\n",
    "list1 = [[1, 2, 3, 4, 5], [3,6,7]]\n",
    "list2 = [[2, 3], [3,4]]\n",
    "# list2 = [[2, 3], [3,4]]\n",
    "def idk2(list1, list2):\n",
    "    aha = []\n",
    "    for l2 in list2:\n",
    "        for l1 in list1:\n",
    "            result = remove_subsequence_if_exists(l1, l2)\n",
    "            if type(result) == tuple:\n",
    "                #FIX THE PROBLEM\n",
    "                list1[list1.index(l1)] = result[1]\n",
    "                aha.append(result[0])\n",
    "            # print(list1.index(l1), result)\n",
    "            else:\n",
    "                list1[list1.index(l1)] = result\n",
    "            aha\n",
    "            \n",
    "            # print(list1)\n",
    "            \n",
    "    return list1+aha+list2 \n",
    "\n",
    "# x1 = idk2(list1, list2)\n",
    "# x2 = idk2(list1, list2)\n",
    "# paths = [x1] + [x2]\n",
    "# paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path(neuron_segments, paths):\n",
    "    final_path=[]\n",
    "    for index, path in enumerate(paths):\n",
    "        temp_path = []\n",
    "        temp_path = idk2(neuron_segments[index], path)\n",
    "        final_path.append(temp_path)\n",
    "\n",
    "    return final_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "connected to arkouda server tcp://*:5555\n",
      "disconnected from arkouda server tcp://*:5555\n",
      "connected to arkouda server tcp://*:5555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Mappings found: 17\n",
      "[[1703, 1941], [1199, 1703], [1941, 1947], [990, 1072], [856, 990], [1072, 1255]] [720575940634524441, 720575940634524441, 720575940634524441, 720575940622927541, 720575940622927541, 720575940622927541]\n",
      "[1703, 1736, 1764, 1795, 1801, 1829, 1839, 1847, 1844, 1832, 1845, 1868, 1927, 1930, 1941]\n",
      "[1199, 1222, 1259, 1315, 1400, 1413, 1443, 1539, 1570, 1703]\n",
      "[1941, 1947]\n",
      "[990, 1004, 1015, 1034, 1050, 1043, 1056, 1072]\n",
      "[856, 858, 864, 870, 866, 869, 881, 900, 904, 911, 917, 925, 944, 975, 983, 990]\n",
      "[1072, 1091, 1097, 1116, 1125, 1138, 1164, 1173, 1199, 1208, 1225, 1241, 1255]\n"
     ]
    }
   ],
   "source": [
    "src, dst, branch_type = drawing_transformation(branches, synapses)\n",
    "dicts = {\n",
    "    \"src\": src,\n",
    "    \"dst\": dst,\n",
    "    \"connection_type\": branch_type\n",
    "    }\n",
    "\n",
    "ak.connect()\n",
    "subgraph = ar.PropGraph()\n",
    "df = ak.DataFrame(dicts)\n",
    "subgraph.load_edge_attributes(df, source_column=\"src\", destination_column=\"dst\", \n",
    "                            relationship_columns=[\"connection_type\"])\n",
    "ak.disconnect()\n",
    "\n",
    "m = findd(g, subgraph)\n",
    "mapping = m[0]\n",
    "\n",
    "src_mapped, dst_mapped = mapping_edges(subgraph, mapping)\n",
    "# print(src_mapped)\n",
    "# print(dst_mapped)\n",
    "\n",
    "new_edges, n_ids = back_transformation_edges(d, src_mapped, dst_mapped)\n",
    "print(new_edges, n_ids)\n",
    "# n_ids = [720575940622927541, 720575940622927541, 720575940622927541, 720575940634524441, 720575940634524441, 720575940634524441]\n",
    "paths, short_ids, nds_neurons = get_slabs(new_edges, n_ids)\n",
    "\n",
    "neuron_nodes, neuron_edges, neuron_segments = normalize_neuron_list(nds_neurons)\n",
    "\n",
    "final_path = get_path(neuron_segments, paths)\n",
    "\n",
    "final_path = [[j for j in i if len(j) >= 2] for i in final_path]\n",
    "\n",
    "testlist = get_segment_idx_nds(final_path, paths)\n",
    "\n",
    "unique_n_ids = set(n_ids)\n",
    "# filtered_rows = neuron3d[0].connectors[neuron3d[0].connectors['partner_id'].isin(unique_n_ids)]\n",
    "filtered_rows = nds_neurons[0].connectors[nds_neurons[0].connectors['partner_id'].isin(unique_n_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>dst</th>\n",
       "      <th>connection_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10002</td>\n",
       "      <td>100020</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20003</td>\n",
       "      <td>200030</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><p>2 rows x 3 columns</p>"
      ],
      "text/plain": [
       "     src     dst connection_type\n",
       "4  10002  100020               s\n",
       "5  20003  200030               s (2 rows x 3 columns)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"connection_type\"] == \"s\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([11991703, 17031941]), array([8560990, 9901072]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synapse_src = df[df[\"connection_type\"] == \"s\"].src.values.to_ndarray()\n",
    "synapse_src = np.vectorize(mapping.get)(synapse_src)\n",
    "synapse_dst = df[df[\"connection_type\"] == \"s\"].dst.values.to_ndarray()\n",
    "synapse_dst = np.vectorize(mapping.get)(synapse_dst)\n",
    "synapse_src , synapse_dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>dst</th>\n",
       "      <th>s_bef</th>\n",
       "      <th>s_bef_x</th>\n",
       "      <th>s_bef_y</th>\n",
       "      <th>s_bef_z</th>\n",
       "      <th>s_af</th>\n",
       "      <th>s_af_x</th>\n",
       "      <th>s_af_y</th>\n",
       "      <th>s_af_z</th>\n",
       "      <th>...</th>\n",
       "      <th>d_af</th>\n",
       "      <th>d_af_x</th>\n",
       "      <th>d_af_y</th>\n",
       "      <th>d_af_z</th>\n",
       "      <th>d_x</th>\n",
       "      <th>d_y</th>\n",
       "      <th>d_z</th>\n",
       "      <th>d_distance</th>\n",
       "      <th>n_id</th>\n",
       "      <th>connection_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17031941</td>\n",
       "      <td>9901072</td>\n",
       "      <td>1703</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1941</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1072</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>754392.0</td>\n",
       "      <td>222796.0</td>\n",
       "      <td>118480.0</td>\n",
       "      <td>1498.111511</td>\n",
       "      <td>720575940634524441_720575940622927541</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11991703</td>\n",
       "      <td>8560990</td>\n",
       "      <td>1199</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1703</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>990</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>753388.0</td>\n",
       "      <td>222332.0</td>\n",
       "      <td>118760.0</td>\n",
       "      <td>1715.436039</td>\n",
       "      <td>720575940634524441_720575940622927541</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        src      dst  s_bef  s_bef_x  s_bef_y  s_bef_z  s_af  s_af_x  s_af_y  \\\n",
       "0  17031941  9901072   1703        0        0        0  1941       0       0   \n",
       "1  11991703  8560990   1199        0        0        0  1703       0       0   \n",
       "\n",
       "   s_af_z  ...  d_af  d_af_x  d_af_y  d_af_z       d_x       d_y       d_z  \\\n",
       "0       0  ...  1072       0       0       0  754392.0  222796.0  118480.0   \n",
       "1       0  ...   990       0       0       0  753388.0  222332.0  118760.0   \n",
       "\n",
       "    d_distance                                   n_id  connection_type  \n",
       "0  1498.111511  720575940634524441_720575940622927541                s  \n",
       "1  1715.436039  720575940634524441_720575940622927541                s  \n",
       "\n",
       "[2 rows x 28 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_pandas = d.to_pandas()\n",
    "synapses = pd.DataFrame({'src': synapse_src, 'dst': synapse_dst})\n",
    "\n",
    "result = pd.merge(d_pandas, synapses, on=['src', 'dst'], how='inner')\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_rows1 = n[720575940634524441]['c'][n[720575940634524441]['c']['partner_id'] == 720575940622927541]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>connector_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>cleft_score</th>\n",
       "      <th>partner_id</th>\n",
       "      <th>type</th>\n",
       "      <th>node_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>64</td>\n",
       "      <td>754.392</td>\n",
       "      <td>222.796</td>\n",
       "      <td>118.48</td>\n",
       "      <td>147</td>\n",
       "      <td>720575940622927541</td>\n",
       "      <td>pre</td>\n",
       "      <td>1795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>284</td>\n",
       "      <td>753.388</td>\n",
       "      <td>222.332</td>\n",
       "      <td>118.76</td>\n",
       "      <td>145</td>\n",
       "      <td>720575940622927541</td>\n",
       "      <td>pre</td>\n",
       "      <td>1703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     connector_id        x        y       z  cleft_score          partner_id  \\\n",
       "58             64  754.392  222.796  118.48          147  720575940622927541   \n",
       "241           284  753.388  222.332  118.76          145  720575940622927541   \n",
       "\n",
       "    type  node_id  \n",
       "58   pre     1795  \n",
       "241  pre     1703  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filt1 = filtered_rows1[((filtered_rows1[\"x\"] == (754392.0)) & (filtered_rows1[\"y\"] == (222796.0))) | ((filtered_rows1[\"x\"] == (753388.0)) & (filtered_rows1[\"y\"] == (222332.0))) | ((filtered_rows1[\"x\"] == (752600.0)) & (filtered_rows1[\"y\"] == (228184.0)))]\n",
    "\n",
    "x_temp, y_temp, z_temp = [], [], []\n",
    "x_temp.extend(filt1.loc[:, \"x\"])\n",
    "y_temp.extend(filt1.loc[:, \"y\"])\n",
    "z_temp.extend(filt1.loc[:, \"z\"])\n",
    "\n",
    "c_coordinates = np.vstack((x_temp, y_temp, z_temp)).T\n",
    "\n",
    "nt2, ct2 = get_neuron_local(720575940622927541, 3000)\n",
    "\n",
    "n2_synapse_nodes, dists = nt2.snap(c_coordinates)\n",
    "\n",
    "filt1['x'] = normalize_column(filt1['x'])\n",
    "filt1['y'] = normalize_column(filt1['y'])\n",
    "filt1['z'] = normalize_column(filt1['z'])\n",
    "filt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1072, 911]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n2_synapse_nodes.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faebe45264894901ad41606bb7ac5c08",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "Skelescope(axis_local_primary_points=[0, 0, 0, 0, 1, 0], segments={0: {'parent_segment': -1, 'children_segment…"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = Skelescope()\n",
    "viewer.add_neuron(neuron_nodes, filt1, final_path, [\"green\", \"blue\"], testlist)\n",
    "viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n1_synapse_nodes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m synapse_finalid \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[43mn1_synapse_nodes\u001b[49m:\n\u001b[1;32m      3\u001b[0m     ds \u001b[38;5;241m=\u001b[39m navis\u001b[38;5;241m.\u001b[39mdownsample_neuron(nt1, downsampling_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3000\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, preserve_nodes\u001b[38;5;241m=\u001b[39m[index])\n\u001b[1;32m      4\u001b[0m     G \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mDiGraph()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n1_synapse_nodes' is not defined"
     ]
    }
   ],
   "source": [
    "synapse_finalid = []\n",
    "for index in n1_synapse_nodes:\n",
    "    ds = navis.downsample_neuron(nt1, downsampling_factor=3000, inplace=False, preserve_nodes=[index])\n",
    "    G = nx.DiGraph()\n",
    "    edges = ds.edges\n",
    "    G.add_edges_from(edges)\n",
    "    type_index = ds.nodes[ds.nodes[\"node_id\"] == index][\"type\"].values[0]\n",
    "    if type_index == 'end':\n",
    "        successor_temp = next(iter(G.successors(index)), None)\n",
    "        syn_id=index*1000+successor_temp\n",
    "        synapse_finalid.append(syn_id)\n",
    "    elif type_index == 'branch':\n",
    "        predecessor_temp = next(iter(G.predecessors(index)), None)\n",
    "        syn_id=predecessor_temp*1000+index\n",
    "        synapse_finalid.append(syn_id)\n",
    "\n",
    "    else:\n",
    "        successor_temp = next(iter(G.successors(index)), None)\n",
    "        predecessor_temp = next(iter(G.predecessors(index)), None)\n",
    "        syn_id=predecessor_temp*1000+successor_temp\n",
    "        synapse_finalid.append(syn_id)\n",
    "\n",
    "print(len(synapse_finalid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arkouda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
