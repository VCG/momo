{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    _         _                   _       \n",
      "   / \\   _ __| | _____  _   _  __| | __ _ \n",
      "  / _ \\ | '__| |/ / _ \\| | | |/ _` |/ _` |\n",
      " / ___ \\| |  |   < (_) | |_| | (_| | (_| |\n",
      "/_/   \\_\\_|  |_|\\_\\___/ \\__,_|\\__,_|\\__,_|\n",
      "                                          \n",
      "\n",
      "Client Version: v2024.06.21\n"
     ]
    }
   ],
   "source": [
    "import importlib.metadata\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import secrets\n",
    "import hashlib\n",
    "\n",
    "import anywidget\n",
    "import traitlets\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(\"/home/michaelshewarega/Desktop/test/arkouda\"))\n",
    "import arkouda as ak\n",
    "import arachne as ar\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from compcon.create_graph import get_neuron_local\n",
    "from fafbseg import flywire\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arkouda as ak\n",
    "import pandas as pd\n",
    "from vimosketches.src.anywidget_test import Widget\n",
    "from skelescope.skelescope import Skelescope\n",
    "from compcon.create_graph import get_neuron, get_graph, draw_graph, get_neuron_local, overall, draw_connection, draw3d_graph\n",
    "from fafbseg import flywire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(\"/home/michaelshewarega/Desktop/test/arkouda\"))\n",
    "import arkouda as ak\n",
    "import pandas as pd\n",
    "from vimosketches.src.anywidget_test import Widget\n",
    "from skelescope.skelescope import Skelescope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_413926/667459582.py:1: DtypeWarning: Columns (26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"/home/michaelshewarega/Desktop/test/OL_random_2.csv\")\n",
      "connected to arkouda server tcp://*:5555\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/home/michaelshewarega/Desktop/test/OL_random_2.csv\")\n",
    "# df = pd.read_csv(\"/home/michaelshewarega/Desktop/test/demo_output_new.csv\")\n",
    "ak.connect()\n",
    "transformed_dataset = ak.DataFrame(df.to_dict(orient='list'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "193e7e32997946d59fadfa28275d28a0",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "Widget()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sketching_board = Widget(arkouda_df=transformed_dataset)\n",
    "sketching_board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif_json=[{'label': [0, 1],\n",
    "  'properties': ['neuron connection', '#000000'],\n",
    "  'index': 0,\n",
    "  'indices': [0, 1],\n",
    "  'tree': None},\n",
    " {'label': [1, 2],\n",
    "  'properties': ['neuron connection', '#000000'],\n",
    "  'index': 1,\n",
    "  'indices': [1, 2],\n",
    "  'tree': None},\n",
    " {'label': [3, 4],\n",
    "  'properties': ['neuron connection', '#00880A'],\n",
    "  'index': 2,\n",
    "  'indices': [3, 4],\n",
    "  'tree': None},\n",
    " {'label': [4, 5],\n",
    "  'properties': ['neuron connection', '#00880A'],\n",
    "  'index': 3,\n",
    "  'indices': [4, 5],\n",
    "  'tree': None},\n",
    " {'label': [6, 7],\n",
    "  'properties': ['synaptic connection', [0, 1], [3, 4]],\n",
    "  'index': 4,\n",
    "  'indices': [6, 7],\n",
    "  'tree': None}]\n",
    "current_mapping={'1': 1168246304032864,\n",
    " '10002': 706555364679350,\n",
    " '30004': 743213414140636,\n",
    " '40005': 701342235879090}\n",
    "current_nodeid_color_mapping={'720575940627406867': '#000000', '720575940632348995': '#00880A'}\n",
    "\n",
    "# testt skeleton_edges, n_ids, con.to_dict()\n",
    "skeleton_edges=[[1846, 2064], [1250, 1614], [756, 1250], [1742, 1846]]\n",
    "n_ids=[720575940632348995,\n",
    " 720575940627406867,\n",
    " 720575940627406867,\n",
    " 720575940632348995]\n",
    "con=pd.DataFrame.from_dict({'x': {0: 775.228},\n",
    " 'y': {0: 296.988},\n",
    " 'z': {0: 119.12},\n",
    " 'type': {0: 'pre'},\n",
    " 'node_id': {0: -1}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ef03e48c06439fa99c05fd63d37626",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "Skelescope(axis_local_primary_points=[0, 0, 0, 0, 1, 0], highlightedpathslist=[20, 21, 548, 549], segments={0:…"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = Skelescope()\n",
    "# viewer.visualize_motif(transformed_dataset, motif_json, current_mapping, current_nodeid_color_mapping)\n",
    "viewer.visualize_motif(skeleton_edges, n_ids, con, current_nodeid_color_mapping)\n",
    "viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "motif = [{'label': [0, 1],\n",
    "  'properties': ['neuron connection', '#000000'],\n",
    "  'index': 0,\n",
    "  'indices': [0, 1],\n",
    "  'tree': None},\n",
    " {'label': [1, 2],\n",
    "  'properties': ['neuron connection', '#000000'],\n",
    "  'index': 1,\n",
    "  'indices': [1, 2],\n",
    "  'tree': None},\n",
    " {'label': [1, 3],\n",
    "  'properties': ['neuron connection', '#000000'],\n",
    "  'index': 2,\n",
    "  'indices': [1, 3],\n",
    "  'tree': None},\n",
    " {'label': [1, 4],\n",
    "  'properties': ['neuron connection', '#000000'],\n",
    "  'index': 3,\n",
    "  'indices': [1, 4],\n",
    "  'tree': None},\n",
    " {'label': [5, 6],\n",
    "  'properties': ['neuron connection', '#00880A'],\n",
    "  'index': 4,\n",
    "  'indices': [5, 6],\n",
    "  'tree': None},\n",
    " {'label': [7, 8],\n",
    "  'properties': ['neuron connection', '#003090'],\n",
    "  'index': 5,\n",
    "  'indices': [7, 8],\n",
    "  'tree': None},\n",
    " {'label': [9, 10],\n",
    "  'properties': ['synaptic connection', [0, 1], [5, 6]],\n",
    "  'index': 6,\n",
    "  'indices': [9, 10],\n",
    "  'tree': None},\n",
    " {'label': [11, 12],\n",
    "  'properties': ['synaptic connection', [1, 2], [7, 8]],\n",
    "  'index': 7,\n",
    "  'indices': [11, 12],\n",
    "  'tree': None}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "motif_json = [{'label': [0, 1],\n",
    "  'properties': ['neuron connection', '#000000'],\n",
    "  'index': 0,\n",
    "  'indices': [0, 1],\n",
    "  'tree': None},\n",
    " {'label': [1, 2],\n",
    "  'properties': ['neuron connection', '#000000'],\n",
    "  'index': 1,\n",
    "  'indices': [1, 2],\n",
    "  'tree': None},\n",
    " {'label': [3, 4],\n",
    "  'properties': ['neuron connection', \"#00880A\"],\n",
    "  'index': 2,\n",
    "  'indices': [3, 4],\n",
    "  'tree': None},\n",
    " {'label': [5, 6],\n",
    "  'properties': ['neuron connection', '#003090'],\n",
    "  'index': 3,\n",
    "  'indices': [5, 6],\n",
    "  'tree': None},\n",
    " {'label': [7, 8],\n",
    "  'properties': ['synaptic connection', [1, 2], [5, 6]],\n",
    "  'index': 4,\n",
    "  'indices': [7, 8],\n",
    "  'tree': None},\n",
    " {'label': [9, 10],\n",
    "  'properties': ['synaptic connection', [0, 1], [3, 4]],\n",
    "  'index': 5,\n",
    "  'indices': [9, 10],\n",
    "  'tree': None}]\n",
    "current_mapping = {'1': 1168246304032864,\n",
    " '10002': 706555364679350,\n",
    " '30004': 743213414140636,\n",
    " '50006': 771040516644241}\n",
    "current_nodeid_color_mapping = {'720575940627406867': '#000000',\n",
    " '720575940632348995': '#00880A',\n",
    " '720575940618698781': '#003090'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_segment_idx_nds(final_segment_paths, paths_with_slabs):\n",
    "    offset = 0\n",
    "    highlighted_path = []\n",
    "    for path in final_segment_paths:\n",
    "        for segment_idx, segment in enumerate(path):\n",
    "            for pws in paths_with_slabs:\n",
    "                for p in pws:\n",
    "                    if segment == p:\n",
    "                        highlighted_path.append(offset + segment_idx)\n",
    "                        \n",
    "        offset += len(path)\n",
    "    return highlighted_path\n",
    "\n",
    "# This function takes two lists, `list1` (the \"host\") and `list2` (the \"sub\").\n",
    "# It checks if `list2` appears within `list1` and returns `list1` split around `list2`:\n",
    "# - Example 1: list1 = [1, 2, 3, 4], list2 = [1, 2] => Output: [2, 3, 4]\n",
    "# - Example 2: list1 = [1, 2, 3, 4], list2 = [2, 3] => Output: ([1, 2], [3, 4])\n",
    "# - Example 3: list1 = [1, 2, 3, 4], list2 = [3, 4] => Output: [1, 2, 3]\n",
    "\n",
    "def remove_subsequence_if_exists(list1, list2):\n",
    "    # Find the starting index of list2 in list1\n",
    "    n, m = len(list1), len(list2)\n",
    "    \n",
    "    # Iterate over list1 to find a matching subsequence\n",
    "    for i in range(n - m + 1):\n",
    "        if list1[i:i + m] == list2:  # Check if list2 matches list1 starting at index i\n",
    "            if i==0:\n",
    "                # print(list1[i + m-1:])\n",
    "                return list1[i + m-1:]\n",
    "            \n",
    "            if (i+m) == len(list1):\n",
    "                return list1[:i+1]\n",
    "            \n",
    "            return list1[:i+1], list1[i + m-1:]  # Remove the subsequence\n",
    "    \n",
    "    return list1\n",
    "\n",
    "def modify_neuron_segments(neuron_segments, paths_with_slabs):\n",
    "    temp_storage = []\n",
    "    for pws in paths_with_slabs:\n",
    "        for ns in neuron_segments:\n",
    "            result = remove_subsequence_if_exists(ns, pws)\n",
    "            if type(result) == tuple:\n",
    "                #FIX THE PROBLEM\n",
    "                neuron_segments[neuron_segments.index(ns)] = result[1]\n",
    "                temp_storage.append(result[0])\n",
    "            \n",
    "            else:\n",
    "                neuron_segments[neuron_segments.index(ns)] = result\n",
    "            \n",
    "    return neuron_segments+temp_storage+paths_with_slabs \n",
    "\n",
    "def get_final_segment_paths(neuron_segments, paths_with_slabs):\n",
    "    \n",
    "    final_segment_paths=[]\n",
    "    for index, path in enumerate(paths_with_slabs):\n",
    "        temp_path = []\n",
    "        temp_path = modify_neuron_segments(neuron_segments[index], path)\n",
    "        final_segment_paths.append(temp_path)\n",
    "\n",
    "    return final_segment_paths\n",
    "\n",
    "def normalize_column(column):\n",
    "    return (column) / (1000)\n",
    "\n",
    "def normalize_neuron_list(not_ds_neurons):\n",
    "    neuron_nodes = []\n",
    "    neuron_edges = []\n",
    "    neuron_segments = []\n",
    "    for n in not_ds_neurons:\n",
    "        n.nodes['x'] = normalize_column(n.nodes['x'])\n",
    "        n.nodes['y'] = normalize_column(n.nodes['y'])\n",
    "        n.nodes['z'] = normalize_column(n.nodes['z'])\n",
    "\n",
    "        # n.connectors['x'] = normalize_column(n.connectors['x'])\n",
    "        # n.connectors['y'] = normalize_column(n.connectors['y'])\n",
    "        # n.connectors['z'] = normalize_column(n.connectors['z'])\n",
    "\n",
    "        n.nodes.radius = 0.1\n",
    "        neuron_nodes.append(n.nodes)\n",
    "        neuron_edges.append(n.edges)\n",
    "        neuron_segments.append(n.segments)\n",
    "    \n",
    "    return neuron_nodes, neuron_edges, neuron_segments\n",
    "\n",
    "def get_slabs(skeleton_edges, n_ids):\n",
    "    print(n_ids)\n",
    "    paths_with_slabs = []\n",
    "    unique_n_ids = set(n_ids)\n",
    "    print(unique_n_ids)\n",
    "    path_ids = []\n",
    "    not_ds_neurons = []\n",
    "\n",
    "    for index, id in enumerate(unique_n_ids):\n",
    "        n = get_neuron_local(id, 3000)\n",
    "        nx_display = nx.Graph()\n",
    "        nx_display.add_edges_from(n.edges)\n",
    "        \n",
    "        shortest_path=[]\n",
    "        temp_path=[]\n",
    "        for edge_index, edge in enumerate(skeleton_edges):\n",
    "            if n_ids[edge_index]==id:\n",
    "                start_node_id = skeleton_edges[edge_index][0]\n",
    "                end_node_id = skeleton_edges[edge_index][1]\n",
    "                try:\n",
    "                    shortest_path = nx.shortest_path(nx_display, source=start_node_id, target=end_node_id, weight='weight')\n",
    "                    \n",
    "                except nx.NetworkXNoPath:\n",
    "                    print(f\"No path found between and\")\n",
    "\n",
    "                temp_path.append(shortest_path)\n",
    "                path_ids.extend([id])\n",
    "        not_ds_neurons.append(n)\n",
    "        paths_with_slabs.append(temp_path)\n",
    "    return paths_with_slabs, path_ids, not_ds_neurons, unique_n_ids\n",
    "\n",
    "def back_transformation_edges(d, src_mapped, dst_mapped):\n",
    "    skeleton_edges = []\n",
    "    neuron_ids = []\n",
    "    x_syn, y_syn, z_syn = [], [], []\n",
    "    for i in range(len(src_mapped)):\n",
    "        df_temp = d[(d['dst'] == src_mapped[i]) & (d['src'] == dst_mapped[i])][0]\n",
    "        if df_temp[\"connection_type\"] == 'n':\n",
    "            new_element = [df_temp[\"s_bef\"], df_temp[\"s_af\"]]\n",
    "            # wenn edges in verschiedenen neurons gleiche ids haben geht das nicht!!(check if neuron_ids übereinstimmen!)\n",
    "            if new_element not in skeleton_edges:\n",
    "                skeleton_edges.append(new_element)\n",
    "                neuron_ids.append(int(df_temp[\"n_id\"]))\n",
    "\n",
    "            new_element = [df_temp[\"d_bef\"], df_temp[\"d_af\"]]\n",
    "            if new_element not in skeleton_edges:\n",
    "                skeleton_edges.append(new_element)\n",
    "                neuron_ids.append(int(df_temp[\"n_id\"]))\n",
    "\n",
    "        else:\n",
    "            x_syn.append(df_temp[\"d_x\"])\n",
    "            y_syn.append(df_temp[\"d_y\"])\n",
    "            z_syn.append(df_temp[\"d_z\"])\n",
    "            new_element = [df_temp[\"s_bef\"], df_temp[\"s_af\"]]\n",
    "            # wenn edges in verschiedenen neurons gleiche ids haben geht das nicht!!(check if neuron_ids übereinstimmen!)\n",
    "            if new_element not in skeleton_edges:\n",
    "                skeleton_edges.append(new_element)\n",
    "                string = df_temp[\"n_id\"]\n",
    "                num1, num2 = map(int, string.split(\"_\"))\n",
    "                neuron_ids.append(num1)\n",
    "\n",
    "            new_element = [df_temp[\"d_bef\"], df_temp[\"d_af\"]]\n",
    "            if new_element not in skeleton_edges:\n",
    "                skeleton_edges.append(new_element)\n",
    "                string = df_temp[\"n_id\"]\n",
    "                num1, num2 = map(int, string.split(\"_\"))\n",
    "                neuron_ids.append(num2)\n",
    "            \n",
    "    data = {\n",
    "            'x': x_syn,    # Wrap the list in an extra list to create a single row\n",
    "            'y': y_syn,\n",
    "            'z': z_syn,\n",
    "            'type': [\"pre\"]*len(x_syn),\n",
    "            'node_id': [-1]*len(x_syn)\n",
    "        }\n",
    "\n",
    "    # Create the DataFrame\n",
    "    con = pd.DataFrame(data)\n",
    "    con['x'] = normalize_column(con['x'])\n",
    "    con['y'] = normalize_column(con['y'])\n",
    "    con['z'] = normalize_column(con['z'])\n",
    "\n",
    "\n",
    "    return skeleton_edges, neuron_ids, con\n",
    "\n",
    "def mapping_edges(subgraph, mapping):\n",
    "    edges = subgraph.edges()\n",
    "    src = edges[0].to_ndarray()\n",
    "    dst = edges[1].to_ndarray()\n",
    "\n",
    "    src = src.astype(str)\n",
    "    dst = dst.astype(str)\n",
    "\n",
    "    src_mapped = np.vectorize(mapping.get)(src)\n",
    "    dst_mapped = np.vectorize(mapping.get)(dst)\n",
    "\n",
    "    return src_mapped, dst_mapped\n",
    "\n",
    "def test_graph_creation(edges):\n",
    "    first_elements = edges[:, 0]\n",
    "    second_elements = edges[:, 1]\n",
    "    neighbor_matrix = (first_elements[:, np.newaxis] == second_elements[np.newaxis, :])\n",
    "\n",
    "    # Step 3: Extract neighbor pairs\n",
    "    neighbor_indices = np.argwhere(neighbor_matrix)\n",
    "    neighbor_indices = neighbor_indices[neighbor_indices[:, 0] != neighbor_indices[:, 1]]\n",
    "    neighbor_pairs = edges[neighbor_indices]\n",
    "\n",
    "    # Step 4: Combine node indices to create unique identifiers for edges\n",
    "    src_combined = neighbor_pairs[:, 0, 0] * 10000 + neighbor_pairs[:, 0, 1]\n",
    "    dst_combined = neighbor_pairs[:, 1, 0] * 10000 + neighbor_pairs[:, 1, 1]\n",
    "\n",
    "    # Convert to lists for Arkouda\n",
    "    src = src_combined.astype(np.int64).tolist()\n",
    "    dst = dst_combined.astype(np.int64).tolist()\n",
    "    return src, dst\n",
    "\n",
    "def drawing_transformation(branches, synapses):\n",
    "    nodes=[]\n",
    "    branch_type= []\n",
    "\n",
    "    for b in branches:\n",
    "        nodes.append(b[0] * 10000 + b[1])\n",
    "\n",
    "    src, dst = test_graph_creation(branches)\n",
    "    for s in src:\n",
    "        branch_type.append(\"n\")\n",
    "\n",
    "    for s in synapses:\n",
    "        src.append(s[0][0] * 10000 + s[0][1])\n",
    "        dst.append(s[1][0] * 10000 + s[1][1])\n",
    "        branch_type.append(\"s\")\n",
    "    \n",
    "    return src, dst, branch_type\n",
    "\n",
    "tast = []\n",
    "def overfinal(d, motif, mapping):\n",
    "# def overfinal(d, src_mapped, dst_mapped):\n",
    "    ak.connect()\n",
    "    branches, synapses = [], []\n",
    "    for m in motif:\n",
    "        if m[\"properties\"][0] == \"neuron connection\":\n",
    "            branches.append(m[\"label\"])\n",
    "            \n",
    "        if m[\"properties\"][0] == \"synaptic connection\":\n",
    "            synapses.append([m[\"properties\"][1], m[\"properties\"][2]])\n",
    "        # print(type((m[\"properties\"][0])))\n",
    "    \n",
    "    branches = np.array(branches)\n",
    "    synapses = np.array(synapses)\n",
    "\n",
    "    src, dst, branch_type = drawing_transformation(branches, synapses)\n",
    "    \n",
    "    dicts = {\n",
    "        \"src\": src,\n",
    "        \"dst\": dst,\n",
    "        \"connection_type\": branch_type\n",
    "        }\n",
    "    print(src, dst)\n",
    "    subgraph = ar.PropGraph()\n",
    "    df = ak.DataFrame(dicts)\n",
    "    subgraph.load_edge_attributes(df, source_column=\"src\", destination_column=\"dst\", \n",
    "                                relationship_columns=[\"connection_type\"])\n",
    "    src_mapped, dst_mapped = mapping_edges(subgraph, mapping)\n",
    "    print(src_mapped, dst_mapped)\n",
    "    \n",
    "    skeleton_edges, n_ids, con = back_transformation_edges(d, src_mapped, dst_mapped)\n",
    "   \n",
    "    paths_with_slabs, path_ids, not_ds_neurons, unique_n_ids = get_slabs(skeleton_edges, n_ids)\n",
    "    \n",
    "    neuron_nodes, neuron_edges, neuron_segments = normalize_neuron_list(not_ds_neurons)\n",
    "    \n",
    "    org_n = []\n",
    "    add_edges = []\n",
    "    tast=[]\n",
    "    for nds in not_ds_neurons:\n",
    "        num=0\n",
    "        n = get_neuron_local(nds.id)\n",
    "        org_n.append(n)\n",
    "        # Convert sublists to tuples to use set operations\n",
    "        n_segments_set = set(map(tuple, n.edges))\n",
    "        np_segments_set = set(map(tuple, nds.edges))\n",
    "        \n",
    "        # Find the difference\n",
    "        difference_set = n_segments_set - np_segments_set\n",
    "    \n",
    "        # Convert the result back to a list of lists\n",
    "        difference = list(map(list, difference_set))\n",
    "        # difference.sort()\n",
    "        # add_edges.append(difference)\n",
    "        # difference = np.array(difference)\n",
    "        # difference = difference[difference[:, 0].argsort()]\n",
    "        tast.append(difference)\n",
    "        segments = []\n",
    "        visited = set()\n",
    "        def build_segment(start, segment):\n",
    "            for edge in difference:\n",
    "                if edge[0] == start and edge[0] not in visited:\n",
    "                    # if edge[0] == 12:\n",
    "                    # print(edge[0])\n",
    "                    segment.append(edge[0])\n",
    "                    visited.add(edge[0])\n",
    "                    return build_segment(edge[1], segment)\n",
    "            # Append last node in segment\n",
    "            if start not in visited:\n",
    "                # print(start)\n",
    "                segment.append(start)\n",
    "                visited.add(start)\n",
    "        \n",
    "        for edge in difference:\n",
    "            if edge[0] not in visited:\n",
    "                segment = []\n",
    "                build_segment(edge[0], segment)\n",
    "                if len(segment) == 1:\n",
    "                    segment.append(edge[1])\n",
    "                segments.append(segment)\n",
    "\n",
    "            elif edge[1] not in visited:\n",
    "                # print(edge[1])\n",
    "                segment = []\n",
    "                segment.append(edge[0])\n",
    "                segment.append(edge[1])\n",
    "                segments.append(segment)\n",
    "            else:\n",
    "        \n",
    "                ii=0\n",
    "                # Iterate over list1 to find a matching subsequence\n",
    "                for element in segments:\n",
    "                    n, m = len(element), len(edge)\n",
    "                    \n",
    "                    for i in range(n - m + 1):\n",
    "                        if element[i:i + m] == edge:  # Check if list2 matches list1 starting at index i\n",
    "                            ii=1\n",
    "                            break\n",
    "                    if ii == 1:\n",
    "                        break\n",
    "                if ii == 0:\n",
    "                    segment= []\n",
    "                    segment.append(edge[0])\n",
    "                    segment.append(edge[1])\n",
    "                    segments.append(segment)\n",
    "                    \n",
    "        add_edges.append(segments)\n",
    "        \n",
    "    o_neuron_nodes, o_neuron_edges, o_neuron_segments = normalize_neuron_list(org_n)\n",
    "    \n",
    "    final_segment_paths = get_final_segment_paths(neuron_segments, paths_with_slabs)\n",
    "\n",
    "    for j in range(len(add_edges)):\n",
    "        final_segment_paths[j] = final_segment_paths[j] + add_edges[j]\n",
    "        # paths_with_slabs[j] = paths_with_slabs[j] + add_edges[j]\n",
    "        \n",
    "    final_segment_paths = [[j for j in i if len(j) >= 2] for i in final_segment_paths]\n",
    "    \n",
    "    highlighted_paths = get_segment_idx_nds(final_segment_paths, paths_with_slabs)\n",
    "    highlighted_paths_twigs = get_segment_idx_nds(final_segment_paths, add_edges)\n",
    "    \n",
    "    ak.disconnect()\n",
    "\n",
    "    return o_neuron_nodes, final_segment_paths, highlighted_paths, highlighted_paths_twigs, con, tast, paths_with_slabs, unique_n_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_post_processed_mappings(g, subgraph_src, subgraph_dst, color, mapping):\n",
    "    start = time.time()\n",
    "    dict_to_check_against = {}\n",
    "    for c in color:\n",
    "        if c not in dict_to_check_against:\n",
    "            dict_to_check_against[c] = 1\n",
    "        else:\n",
    "            dict_to_check_against[c] += 1\n",
    "\n",
    "    isos_by_vertices = mapping[0]\n",
    "    isos_by_edges_src = mapping[1][0]\n",
    "    isos_by_edges_dst = mapping[1][1]\n",
    "    \n",
    "    num_edges_subgraph = len(subgraph_src)\n",
    "    number_isos_found = len(isos_by_edges_src) // len(subgraph_src)\n",
    "\n",
    "    indices = ak.find([isos_by_edges_src,isos_by_edges_dst],[g.edge_attributes[\"src\"], g.edge_attributes[\"dst\"]])\n",
    "    vals = g.edge_attributes[\"n_id\"][indices]\n",
    "\n",
    "    # TODO: Can the below be done with Arkouda?\n",
    "    isos_by_edges_src_ndarray = np.split(isos_by_edges_src.to_ndarray(), number_isos_found)\n",
    "    isos_by_edges_dst_ndarray = np.split(isos_by_edges_dst.to_ndarray(), number_isos_found)\n",
    "    vals_ndarray = np.split(vals.to_ndarray(), number_isos_found)\n",
    "\n",
    "    matches = 0\n",
    "    curr_mapping_id = 0\n",
    "    final_mappings = []\n",
    "    for src,dst,vals in zip(isos_by_edges_src_ndarray,isos_by_edges_dst_ndarray,vals_ndarray):\n",
    "        inner_matches = {}\n",
    "        for val in vals:\n",
    "            if val not in inner_matches:\n",
    "                inner_matches[val] = 1\n",
    "            else:\n",
    "                inner_matches[val] += 1\n",
    "        if sorted(inner_matches.values()) == sorted(dict_to_check_against.values()):\n",
    "            final_mappings.append(isos_by_vertices[curr_mapping_id])\n",
    "            matches += 1\n",
    "        curr_mapping_id += 1\n",
    "\n",
    "    end = time.time()\n",
    "    print(f\"Before post processing number of motifs found was {number_isos_found} and after was {matches}\")\n",
    "    print(f\"Post processing took: {end-start} seconds.\")\n",
    "\n",
    "    return final_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.metadata\n",
    "import pathlib\n",
    "import anywidget\n",
    "import traitlets\n",
    "import arkouda as ak\n",
    "import arachne as ar\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "try:\n",
    "    __version__ = importlib.metadata.version(\"anywidget_test\")\n",
    "except importlib.metadata.PackageNotFoundError:\n",
    "    __version__ = \"unknown\"\n",
    "\n",
    "def get_mapping(g, subgraph, iso_cap):\n",
    "    # Process subgraph information for mapping after subgraph isomorphism is invoked.\n",
    "    src_sub, dst_sub = subgraph.edges()\n",
    "    src_sub = src_sub.to_ndarray()\n",
    "    dst_sub = dst_sub.to_ndarray()\n",
    "    subgraph_nodes = sorted(list(np.unique(np.concatenate((src_sub, dst_sub)))))\n",
    "\n",
    "    start = time.time()\n",
    "    if iso_cap > 0 :\n",
    "        isos = ar.subgraph_isomorphism(g, subgraph, algorithm_type=\"si\", return_isos_as=\"complete\", semantic_check=\"or\", size_limit=iso_cap)\n",
    "    else:\n",
    "        isos = ar.subgraph_isomorphism(g, subgraph, algorithm_type=\"si\", return_isos_as=\"complete\", semantic_check=\"or\")\n",
    "    end = time.time()\n",
    "    \n",
    "    # Extract the returned array information from subgraph_isomorphism.\n",
    "    isos_by_vertices = isos[0]\n",
    "    isos_by_vertices_map = isos[1]\n",
    "    isos_by_edges_src = isos[2]\n",
    "    isos_by_edges_dst = isos[3]\n",
    "\n",
    "    if len(isos_by_vertices) % len(subgraph) != 0:\n",
    "        raise ValueError(\"The length of isomorphisms is not a multiple of the number of subgraph nodes.\")\n",
    "\n",
    "    # Get the number of motifs found.\n",
    "    number_isos_found = len(isos_by_vertices) // len(subgraph_nodes)\n",
    "    print(f\"Finding {number_isos_found:_} motifs took: {end-start} seconds.\")\n",
    "\n",
    "    # Prepare the returned isomorphisms as a 2D array.\n",
    "    start = time.time()\n",
    "    isos_ndarray = isos_by_vertices.to_ndarray()\n",
    "    hostgraph_nodes = isos_ndarray.reshape(-1, len(subgraph_nodes))\n",
    "    end = time.time()\n",
    "    print(f\"Reshaping isomorphisms took: {end-start} seconds.\")\n",
    "\n",
    "    # Create all mappings at once using a list comprehension.\n",
    "    start = time.time()\n",
    "    all_mappings = [\n",
    "        {int(k): int(v) for k, v in zip(subgraph_nodes, hostgraph_nodes[i])}\n",
    "        for i in range(number_isos_found)\n",
    "    ]\n",
    "    end = time.time()\n",
    "    print(f\"Generating mappings took: {end-start} seconds.\")\n",
    "\n",
    "    return (all_mappings,(isos_by_edges_src,isos_by_edges_dst))\n",
    "\n",
    "def test_graph_creation(edges):\n",
    "    first_elements = edges[:, 0]\n",
    "    second_elements = edges[:, 1]\n",
    "    neighbor_matrix = (first_elements[:, np.newaxis] == second_elements[np.newaxis, :])\n",
    "\n",
    "    # Step 3: Extract neighbor pairs\n",
    "    neighbor_indices = np.argwhere(neighbor_matrix)\n",
    "    neighbor_indices = neighbor_indices[neighbor_indices[:, 0] != neighbor_indices[:, 1]]\n",
    "    neighbor_pairs = edges[neighbor_indices]\n",
    "\n",
    "    # Step 4: Combine node indices to create unique identifiers for edges\n",
    "    src_combined = neighbor_pairs[:, 0, 0] * 10000 + neighbor_pairs[:, 0, 1]\n",
    "    dst_combined = neighbor_pairs[:, 1, 0] * 10000 + neighbor_pairs[:, 1, 1]\n",
    "\n",
    "    # Convert to lists for Arkouda\n",
    "    src = src_combined.astype(np.int64).tolist()\n",
    "    dst = dst_combined.astype(np.int64).tolist()\n",
    "    return src, dst\n",
    "\n",
    "def drawing_transformation(branches, synapses, color):\n",
    "    nodes=[]\n",
    "    branch_type= []\n",
    "    id_to_col= {}\n",
    "    con_color=[]\n",
    "\n",
    "    for b in range(len(branches)):\n",
    "        nodes.append(branches[b][0] * 10000 + branches[b][1])\n",
    "        id_to_col[str(branches[b][0] * 10000 + branches[b][1])] = color[b]\n",
    "            \n",
    "    color_mapping = dict(zip(nodes, color))\n",
    "\n",
    "    src, dst = test_graph_creation(branches)\n",
    "    for s in src:\n",
    "        branch_type.append(\"n\")\n",
    "        con_color.append(id_to_col[str(s)]) \n",
    "\n",
    "    for s in synapses:\n",
    "        src.append(s[0][0] * 10000 + s[0][1])\n",
    "        dst.append(s[1][0] * 10000 + s[1][1])\n",
    "        branch_type.append(\"s\")\n",
    "        con_color.append(id_to_col[str(s[0][0] * 10000 + s[0][1])] + \"_\" + id_to_col[str(s[1][0] * 10000 + s[1][1])])\n",
    "    \n",
    "    return src, dst, branch_type, color_mapping, con_color\n",
    "\n",
    "def motif_to_vis(d, motif):\n",
    "    ak.connect()\n",
    "\n",
    "    g = ar.PropGraph()\n",
    "    g.load_edge_attributes(d, source_column=\"src\", destination_column=\"dst\", \n",
    "                               relationship_columns=[\"s_bef\", \"s_bef_x\", \"s_bef_y\", \"s_bef_z\", \"s_af\", \"s_af_x\", \n",
    "                                                     \"s_af_y\", \"s_af_z\", 's_x', \"s_y\", \"s_z\", \"s_distance\", \"d_bef\",\n",
    "                                                     \"d_bef_x\", \"d_bef_y\", \"d_bef_z\", \"d_af\", \"d_af_x\", \"d_af_y\", \"d_af_z\",\n",
    "                                                       \"d_x\", \"d_y\", \"d_z\", \"d_distance\", \"n_id\", \"connection_type\"])\n",
    "    \n",
    "    branches, synapses, color = [], [], []\n",
    "\n",
    "    for m in motif:\n",
    "        if m[\"properties\"][0] == \"neuron connection\":\n",
    "            branches.append(m[\"label\"])\n",
    "            color.append(m[\"properties\"][1])\n",
    "            \n",
    "            \n",
    "        if m[\"properties\"][0] == \"synaptic connection\":\n",
    "            synapses.append([m[\"properties\"][1], m[\"properties\"][2]])\n",
    "    \n",
    "    branches = np.array(branches)\n",
    "    synapses = np.array(synapses)\n",
    "\n",
    "    src, dst, branch_type, color_mapping, con_color = drawing_transformation(branches, synapses, color)\n",
    "    # return dst, src, branch_type, con_color\n",
    "\n",
    "    subgraph_dict = {\n",
    "        \"src\": dst,\n",
    "        \"dst\": src,\n",
    "        \"connection_type\": branch_type\n",
    "        }\n",
    "    print(dst, src)\n",
    "    subgraph = ar.PropGraph()\n",
    "    df = ak.DataFrame(subgraph_dict)\n",
    "    subgraph.load_edge_attributes(df, source_column=\"src\", destination_column=\"dst\", \n",
    "                                relationship_columns=[\"connection_type\"])\n",
    "    cap=10000000\n",
    "    node_mapping = get_mapping(g, subgraph, cap)\n",
    "    final_mapping = get_post_processed_mappings(g, dst, src, con_color, node_mapping)\n",
    "    nodeid_color_mapping=[]\n",
    "    for element in final_mapping[20:40]:\n",
    "        neuron_ids=[]\n",
    "        node_colors=[]\n",
    "        for index in element:\n",
    "            temp_df = d[ (d[\"src\"] == element[index]) & (d[\"connection_type\"] == \"n\")]\n",
    "            \n",
    "            if len(temp_df) == 0:\n",
    "                neuron_id = d[ (d[\"dst\"] == element[index]) & (d[\"connection_type\"] == \"n\")][0][\"n_id\"]\n",
    "                if neuron_id not in neuron_ids:\n",
    "                    neuron_ids.append(neuron_id)\n",
    "                    node_colors.append(color_mapping[index])\n",
    "    \n",
    "            else:\n",
    "                neuron_id = temp_df[0][\"n_id\"]\n",
    "                if neuron_id not in neuron_ids:\n",
    "                    neuron_ids.append(neuron_id)\n",
    "                    node_colors.append(color_mapping[index])\n",
    "        nodeid_color_mapping.append(dict(zip(neuron_ids,node_colors)))\n",
    "    \n",
    "    return node_mapping[0], con_color, final_mapping[10:40], nodeid_color_mapping\n",
    "    # return node_mapping[0], nodeid_color_mapping, con_color, final_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "connected to arkouda server tcp://*:5555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 10002, 20003, 10002, 10002, 70008, 90010] [10002, 20003, 30004, 20005, 20006, 1, 30004]\n",
      "Finding 11_718 motifs took: 10.33528470993042 seconds.\n",
      "Reshaping isomorphisms took: 0.00102996826171875 seconds.\n",
      "Generating mappings took: 0.06152987480163574 seconds.\n",
      "Before post processing number of motifs found was 11718 and after was 9648\n",
      "Post processing took: 0.4869687557220459 seconds.\n"
     ]
    }
   ],
   "source": [
    "node_mapping, con_color, final_mapping, nodeid_color_mapping = motif_to_vis(transformed_dataset, sketching_board.motif_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "connected to arkouda server tcp://*:5555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10002, 40005, 1, 30004] [1, 30004, 60007, 80009]\n",
      "[2499732668717878 2240652335590548 9167518333106490 9086653865494560] [2173212624489644 2499732668717878 2533279942103133 9167518333106490]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error: pdarrayIndexMsg: OOBindex 0 > -1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m neuron_nodes, final_segment_paths, highlighted_paths, highlighted_paths_twigs, con, tast, paths_with_slabs, unique_n_ids \u001b[38;5;241m=\u001b[39m  \u001b[43moverfinal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msketching_board\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmotif_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msketching_board\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_mapping\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 252\u001b[0m, in \u001b[0;36moverfinal\u001b[0;34m(d, motif, mapping)\u001b[0m\n\u001b[1;32m    249\u001b[0m src_mapped, dst_mapped \u001b[38;5;241m=\u001b[39m mapping_edges(subgraph, mapping)\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28mprint\u001b[39m(src_mapped, dst_mapped)\n\u001b[0;32m--> 252\u001b[0m skeleton_edges, n_ids, con \u001b[38;5;241m=\u001b[39m \u001b[43mback_transformation_edges\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_mapped\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m paths_with_slabs, path_ids, not_ds_neurons, unique_n_ids \u001b[38;5;241m=\u001b[39m get_slabs(skeleton_edges, n_ids)\n\u001b[1;32m    256\u001b[0m neuron_nodes, neuron_edges, neuron_segments \u001b[38;5;241m=\u001b[39m normalize_neuron_list(not_ds_neurons)\n",
      "Cell \u001b[0;32mIn[8], line 122\u001b[0m, in \u001b[0;36mback_transformation_edges\u001b[0;34m(d, src_mapped, dst_mapped)\u001b[0m\n\u001b[1;32m    120\u001b[0m x_syn, y_syn, z_syn \u001b[38;5;241m=\u001b[39m [], [], []\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(src_mapped)):\n\u001b[0;32m--> 122\u001b[0m     df_temp \u001b[38;5;241m=\u001b[39m \u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdst\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msrc_mapped\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msrc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdst_mapped\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m df_temp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconnection_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    124\u001b[0m         new_element \u001b[38;5;241m=\u001b[39m [df_temp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms_bef\u001b[39m\u001b[38;5;124m\"\u001b[39m], df_temp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms_af\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n",
      "File \u001b[0;32m~/Desktop/test/arkouda/arkouda/dataframe.py:872\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    870\u001b[0m     row \u001b[38;5;241m=\u001b[39m array([key])\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_columns:\n\u001b[0;32m--> 872\u001b[0m         result[k] \u001b[38;5;241m=\u001b[39m (\u001b[43mUserDict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m]\u001b[49m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Row(result)\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# Select a single column using a string\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/test/arkouda/arkouda/pdarrayclass.py:994\u001b[0m, in \u001b[0;36mpdarray.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    992\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbool\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m!=\u001b[39m key\u001b[38;5;241m.\u001b[39msize:\n\u001b[1;32m    993\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize mismatch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;241m.\u001b[39msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 994\u001b[0m     repMsg \u001b[38;5;241m=\u001b[39m \u001b[43mgeneric_msg\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    995\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcmd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m[pdarray]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    996\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    997\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43marray\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    998\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43midx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    999\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1000\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1001\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m create_pdarray(repMsg)\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mslice\u001b[39m):\n\u001b[1;32m   1004\u001b[0m     \u001b[38;5;66;03m# handle the arr[:] case\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/test/arkouda/arkouda/client.py:1006\u001b[0m, in \u001b[0;36mgeneric_msg\u001b[0;34m(cmd, args, payload, send_binary, recv_binary)\u001b[0m\n\u001b[1;32m   1004\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1005\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m payload \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1006\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mChannel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_string_message\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcmd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecv_binary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecv_binary\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;66;03m# if the user interrupts during command execution, the socket gets out\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;66;03m# of sync reset the socket before raising the interrupt exception\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m     cast(Channel, channel)\u001b[38;5;241m.\u001b[39mconnect(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/test/arkouda/arkouda/client.py:529\u001b[0m, in \u001b[0;36mZmqChannel.send_string_message\u001b[0;34m(self, cmd, recv_binary, args, size, request_id)\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;66;03m# raise errors or warnings sent back from the server\u001b[39;00m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_message\u001b[38;5;241m.\u001b[39mmsgType \u001b[38;5;241m==\u001b[39m MessageType\u001b[38;5;241m.\u001b[39mERROR:\n\u001b[0;32m--> 529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(return_message\u001b[38;5;241m.\u001b[39mmsg)\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m return_message\u001b[38;5;241m.\u001b[39mmsgType \u001b[38;5;241m==\u001b[39m MessageType\u001b[38;5;241m.\u001b[39mWARNING:\n\u001b[1;32m    531\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(return_message\u001b[38;5;241m.\u001b[39mmsg)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error: pdarrayIndexMsg: OOBindex 0 > -1"
     ]
    }
   ],
   "source": [
    "neuron_nodes, final_segment_paths, highlighted_paths, highlighted_paths_twigs, con, tast, paths_with_slabs, unique_n_ids =  overfinal(transformed_dataset, sketching_board.motif_json, sketching_board.current_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 120733157032976,\n",
       " 10002: 81730075459297,\n",
       " 30004: 130140935503168,\n",
       " 40005: 135236815507834,\n",
       " 60007: 880291167309467,\n",
       " 70008: 430709928016090,\n",
       " 90010: 955221373858429,\n",
       " 100011: 1136718985277113}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_mapping[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80c4e7eddba64cb999155dca2fcde80f",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "Skelescope(axis_local_primary_points=[0, 0, 0, 0, 1, 0], segments={0: {'parent_segment': -1, 'children_segment…"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = Skelescope()\n",
    "viewer.add_neuron(neuron_nodes, con, final_segment_paths, [\"black\", \"green\", \"blue\", \"black\"], highlighted_paths, highlighted_paths_twigs)\n",
    "viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "loaded_data={}\n",
    "with open('/home/michaelshewarega/Desktop/test/subgraph5_motifs_capped_at_500.json', 'r') as f:\n",
    "   loaded_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "loaded_data=[\n",
    "  {1: 230597933944620, 10002: 163150316902359, 20003: 151098865808515, 40005: 237178936808301, 60007: 27823523547052, 80009: 36902778599792}, \n",
    "  {1: 429343149753935, 10002: 324929389196380, 20003: 293761102462752, 40005: 380321550838434, 60007: 1046794514334153, 80009: 624902601315828}, \n",
    "  {1: 230597933944620, 10002: 163150316902359, 20003: 151098865808515, 40005: 35755618614405, 60007: 27823523547052, 80009: 36902778599792}, \n",
    "  {1: 230597933944620, 10002: 163150316902359, 20003: 151098865808515, 40005: 237178936808301, 60007: 216072288563180, 80009: 36902778599792}, \n",
    "  {1: 94534633381003, 10002: 86904035170864, 20003: 66979695400248, 40005: 552903031924713, 60007: 64807505142412, 80009: 723827034764983}, \n",
    "  {1: 429343149753935, 10002: 324929389196380, 20003: 293761102462752, 40005: 396459939754203, 60007: 1046794514334153, 80009: 624902601315828}, \n",
    "  {1: 429343149753935, 10002: 324929389196380, 20003: 293761102462752, 40005: 351544664578740, 60007: 1046794514334153, 80009: 624902601315828}, \n",
    "  {1: 230597933944620, 10002: 163150316902359, 20003: 151098865808515, 40005: 35755618614405, 60007: 216072288563180, 80009: 36902778599792}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 429343149753935,  324929389196380,  396459939754203,\n",
       "        1046794514334153,  624902601315828]),\n",
       " array([324929389196380, 293761102462752, 429343149753935, 324929389196380,\n",
       "        293761102462752]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initial lists\n",
    "src = [1, 10002, 40005, 60007, 80009]\n",
    "dst = [10002, 20003, 1, 10002, 20003]\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "src = np.array(src)\n",
    "dst = np.array(dst)\n",
    "\n",
    "# Convert arrays to strings\n",
    "# src = src.astype(str)\n",
    "# dst = dst.astype(str)\n",
    "o=5\n",
    "src_mapped = np.vectorize(loaded_data[o].get)(src)\n",
    "dst_mapped = np.vectorize(loaded_data[o].get)(dst)\n",
    "\n",
    "src_mapped, dst_mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "motif_json = [{'label': [0, 1],\n",
    "  'properties': ['neuron connection', '#00880A'],\n",
    "  'index': 0,\n",
    "  'indices': [0, 1],\n",
    "  'tree': None},\n",
    " {'label': [1, 2],\n",
    "  'properties': ['neuron connection', '#00880A'],\n",
    "  'index': 1,\n",
    "  'indices': [1, 2],\n",
    "  'tree': None},\n",
    " {'label': [3, 4],\n",
    "  'properties': ['neuron connection', '#003090'],\n",
    "  'index': 2,\n",
    "  'indices': [3, 4],\n",
    "  'tree': None},\n",
    " {'label': [4, 5],\n",
    "  'properties': ['neuron connection', '#003090'],\n",
    "  'index': 3,\n",
    "  'indices': [4, 5],\n",
    "  'tree': None},\n",
    " {'label': [6, 7],\n",
    "  'properties': ['synaptic connection', [1, 2], [4, 5]],\n",
    "  'index': 4,\n",
    "  'indices': [6, 7],\n",
    "  'tree': None},\n",
    " {'label': [8, 9],\n",
    "  'properties': ['synaptic connection', [0, 1], [3, 4]],\n",
    "  'index': 5,\n",
    "  'indices': [8, 9],\n",
    "  'tree': None}]\n",
    "\n",
    "# current_mapping = sketching_board.current_mapping \n",
    "\n",
    "current_mapping = {'1': 1970314, '10002': 3141260, '30004': 8530908, '40005': 9081197}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
